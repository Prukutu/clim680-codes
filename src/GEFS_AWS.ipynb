{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEFSv12 Data from the Cloud\n",
    "\n",
    "This notebook demontrates how to:\n",
    "* download a single GEFSv12 re-forecast data file from Amazon Web Services (AWS) without an AWS account - https://registry.opendata.aws/noaa-gefs-reforecast/\n",
    "* how to read it in using `xarray` and plot the data\n",
    "\n",
    "Note there are many other datasets available via AWS e.g. https://aws.amazon.com/blogs/big-data/visualize-over-200-years-of-global-climate-data-using-amazon-athena-and-amazon-quicksight/\n",
    "\n",
    "`boto3` and `botocore` are the Python packages used to access data on AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path  # implements some useful functions on pathnames, see: https://docs.python.org/3/library/os.path.html\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "#import hvplot.xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data on AWS is located in specific locations called `buckets`, so we must specify the bucket we want to look in. \n",
    "\n",
    "The prefix is the list of subdirectories in that `bucket`\n",
    "\n",
    "We got this information from looking through the data on the web interface to find the file we wanted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'noaa-gefs-retrospective'\n",
    "prefix = 'GEFSv12/reforecast/2000/2000010500/c00/Days:1-10/' \n",
    "# year month day hour \n",
    "# c00 ensemble member \n",
    "# first 10 days on high res grid, rather then out to 35 days on lower res grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define filenames for the file the we want to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname = 'pres_msl' # Barometric pressure extrapolated to mean sea level\n",
    "\n",
    "my_userid = os.path.expanduser('~').split('/')[2]  # Get my userid\n",
    "\n",
    "remote_file = f'{prefix}{varname}_2000010500_c00.grib2'\n",
    "local_fname = os.path.basename(remote_file)\n",
    "local_file = f'/scratch/{my_userid}/{local_fname}'\n",
    "\n",
    "print(local_file)\n",
    "print(remote_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access AWS without having an account \n",
    "This will only allow access to open, public datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\n",
    "    's3',\n",
    "    aws_access_key_id='',\n",
    "    aws_secret_access_key='',\n",
    "    config=Config(signature_version=UNSIGNED)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the file from AWS\n",
    "\n",
    "Without an AWS account we can only download the data, we cannot\n",
    "do any calculations with the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.Bucket(BUCKET).download_file(remote_file, local_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in downloaded file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=xr.open_dataset(local_file,engine='cfgrib',\n",
    "                   backend_kwargs={'indexpath': ''})\n",
    "ds['msl']=ds['msl']/100.0  # Convert to hPa\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the time dimensions...\n",
    "\n",
    "This is a model forecast field. \n",
    "There are data saved across a 10-day forecast period at 3-hour intervals (8 times per day), i.e. out to 240 hours from the initial time. \n",
    "The initial state is not included, so there are 80 global 2D arrays, not 81.\n",
    "\n",
    "It has not one, but two separate time coordinates: `time` and `step` - actually there are three, because `valid_time` is a combination of the other two.\n",
    "* `time` is the time of the start of the forecast - when the forecast model was initialized. It is a `datetime64` object.\n",
    "* `step` is the forecast step - the time after the initial time. It is a `timedelta64` object, which behaves differently* than `datetime64`.\n",
    "* `valid_time` is the time the forecast is valid, i.e. the sum of `time` and `step`. It is a `datetime64` object.\n",
    "\n",
    "So, we have a few options for referring to various times in this forecast. We could:\n",
    "1. Refer to sequential steps by their corresponding array indices, from 0 to 79.\n",
    "2. Refer to the validation date and time, using the `valid_time` coordinate.\n",
    "3. Refer to the forecast time _delta_ from the initial time, using the `step` coordinate.\n",
    "\n",
    "All times are in units of $ns$: nanoseconds (billionths of a second). This is the default for timekeeping in `xarray`.\n",
    "\n",
    "*`timedelta64` has fewer attributes than `datetime64`: we can only refer to `days`, `seconds`, `microseconds` and `nanoseconds` when parsing such a dimension.\n",
    "The following would all list the seconds part of the coordinate `step`:\n",
    "\n",
    "`ds.step.dt.seconds`\n",
    "\n",
    "`ds['step'].dt.seconds`\n",
    "\n",
    "`ds['step.seconds']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of tuples, each showing the:\n",
    "#    (index, days, seconds) \n",
    "# corresponding to the forecast time step\n",
    "list(zip(np.arange(len(ds['step'])),ds['step.days'].data,ds['step.seconds'].data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python `datetime` module\n",
    "\n",
    "`datetime` provides us nice functionality to deal with these peculiar time constructs. \n",
    "We can import the `timedelta` and `datetime` classes to give us a more intuitive way to translate times and select forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta, datetime\n",
    "fcst_24 = ds['msl'].sel(step=timedelta(hours=24)) # Choose the 24-hour forecast\n",
    "fcst_24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "ax=plt.axes(projection=ccrs.PlateCarree())\n",
    "cs = ax.contourf(fcst_24.longitude,fcst_24.latitude,fcst_24,transform = ccrs.PlateCarree(),cmap='YlGnBu',extend='both') \n",
    "ax.coastlines() \n",
    "cbar = plt.colorbar(cs,shrink=0.7,aspect=30,orientation='horizontal',label='Sea Level Pressure (hPa)') \n",
    "ic_time = fcst_24.time.dt.strftime('%-d %B %Y at %H%M UTC').item()\n",
    "valid_time = fcst_24.valid_time.dt.strftime('%-d %B %Y at %H%M UTC').item()\n",
    "plt.title(f\"GEFSv12 Reforecast, IC={ic_time}\\nValid: {valid_time}\") ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOAA uses AWS\n",
    "\n",
    "NOAA has a contract with Amazon to make many of its operational and archive products openly available to the public via cloud services. These include _in situ_ observations, satellite data, and model products including forecasts. There is a [registry of data](https://registry.opendata.aws/collab/noaa/) that describes all the products available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clim_data",
   "language": "python",
   "name": "clim_data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
