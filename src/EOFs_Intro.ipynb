{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empircal Orthogonal Function Analysis (EOFs)\n",
    "Also called Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Framing of the problem:\n",
    "\n",
    "In climate, we often have lots of data that varies (and co-varies) in space and time.  For example, we have our monthly precipitation data as time series of maps with dimensions `[time, lat, lon]`. \n",
    "\n",
    "We want to understand the variability of the precipitation and answer questions like: \n",
    "\n",
    "* Why does it rain more or less at times in this location or that location? \n",
    "\n",
    "* What large-scale patterns are there that are associated with more or less rainfall in certain regions?  \n",
    "\n",
    "* Is there any regularity in time about when it rains more or less?\n",
    "\n",
    "It is impossible to look at thousands or tens of thousands of maps or even movies of our data to identify patterns and understand this.\n",
    "\n",
    "__Climate data is complicated because it varies in space and time__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use EOFs to simplify our data\n",
    "\n",
    "We simplify our data by trying to identify the patterns in the data that are associated with the largest amount of variability and we want each of the patterns to be unrelated to each other. \n",
    "\n",
    "__What do I mean by this?__\n",
    "\n",
    "We want to identify some simpler set of spatial patterns (i.e. maps) that explain the most variability and a corresponding timeseries that tells us how that spatial pattern varies.  We want each spatial pattern to tell us something different than the other spatial patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview Summary \n",
    "\n",
    "EOFs will:\n",
    "\n",
    "* Find the spatial patterns of variabilty\n",
    "* Find their time variation\n",
    "* Give a measure of importance of each pattern\n",
    "\n",
    "You can think of EOFs as:\n",
    "\n",
    "* a method for simplifying our data (data reduction method)\n",
    "* a way of identifying spatial and temporal patterns of importance (in terms of variance) in climate data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is it?\n",
    "\n",
    "_Note: This is a high-level explanation designed to not require extensive math.  The detailed mathematical explanation is left for statistics class or this [document]()._\n",
    "\n",
    "It is a way of reducing the complexity of our data by finding a new coordinate system (instead of x,y,z,...) which aligns with the direction of the most variance in the data.  The coordinates where the data has little variance can then be eliminated, reducing the dimensionality and complexity of our data.\n",
    "\n",
    "__Examples__\n",
    "\n",
    "A very graphical explanation is provided [here](https://setosa.io/ev/principal-component-analysis/)\n",
    "\n",
    "In these examples, we could see graphically what is happening for 2D,3D, and sort of for 17D.  In climate we have many more dimensions to our data. For 1x1deg data, we would say we probably have at least 64,800 x,y dimensions + time.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we calculate them (and some terminology)?\n",
    "\n",
    "EOFs are calculated by identifying the most important patterns of variability, and how important they are. The patterns are called `eigenvectors` and their degree of importance is measured in `eigenvalues`. \n",
    "\n",
    "* The `eigenvectors` and `eigenvalues` are calculated from the `covariance matrix`.   \n",
    "\n",
    "* The `covariance matrix` is a way of containing all the information about how the data varies with itself in space and time.\n",
    "\n",
    "* The `eigenvectors` identify the new coordinates in our data where the variance is largest based on our `covariance matrix`. In our problem setup, the new coordinates correspond to the spatial dimensions of our data. An additional constraint called `orthogonality` ensures we identify independent spatial coordinates.\n",
    "\n",
    "* The `eigenvalues` measure the importance of the `eigenvector`, so they tell us a ranking of how important is each spatial pattern identified by the `eigenvectors`.  \n",
    "\n",
    "Given data $X$ with mean removed and with dimensions `[time,space]`, the data can be re-defined based on the new coordinate system in terms of its  spatial part `EOF spatial patterns` and its temporal part `PC timeseries` based on its `eigenvectors`:\n",
    "\n",
    "$ X[space,time] = PC[time,enum] x EOF^T[enum,space] $\n",
    "\n",
    "where \n",
    "\n",
    "* `enum` tells us which `eigenvector`\n",
    "* `space` is all our points in space (`nlons*nlats`)\n",
    "* `time` is all our times `nt`\n",
    "\n",
    "We get the `EOF spatial patterns` from the `eigenvectors` and we get the corresponding `PC time series` by solving for them in the above equation. \n",
    "\n",
    "$ PC[time,mode] = X[time,space] x EOF[space,mode] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (clim680)",
   "language": "python",
   "name": "clim680"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
